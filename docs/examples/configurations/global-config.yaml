# Global Configuration Example
# Located at: ~/.dotnet-prompt/config.yaml (Unix) or %USERPROFILE%\.dotnet-prompt\config.yaml (Windows)

# Default AI provider and model
default_provider: "github"
default_model: "gpt-4o"

# Timeout for requests (in seconds)
timeout: 300

# Cache settings
cache_enabled: true
cache_directory: "~/.dotnet-prompt/cache"

# Telemetry settings
telemetry_enabled: true

# Provider configurations
providers:
  # GitHub Models (default)
  github:
    token: "${GITHUB_TOKEN}"
    base_url: "https://models.inference.ai.azure.com"
  
  # OpenAI
  openai:
    api_key: "${OPENAI_API_KEY}"
    base_url: "https://api.openai.com/v1"
    timeout: 300
    max_retries: 3
  
  # Azure OpenAI
  azure:
    api_key: "${AZURE_OPENAI_API_KEY}"
    endpoint: "${AZURE_OPENAI_ENDPOINT}"
    deployment: "gpt-4"
    api_version: "2024-06-01"
  
  # Anthropic Claude
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    base_url: "https://api.anthropic.com"
  
  # Local Ollama
  ollama:
    base_url: "http://localhost:11434"

# Logging configuration
logging:
  level: "Information"
  console: true
  file: "~/.dotnet-prompt/logs/dotnet-prompt.log"
  structured: false
  include_scopes: false

# Tool-specific configuration
tool_configuration:
  project_analysis:
    include_private_members: false
    max_file_size_bytes: 1048576  # 1MB
    excluded_directories: ["bin", "obj", ".git", "node_modules"]
  
  build_test:
    default_configuration: "Debug"
    verbose_logging: false
    timeout_seconds: 300
    parallel_execution: true
    excluded_test_categories: []
  
  file_system:
    allowed_directories: []
    max_file_size_bytes: 10485760  # 10MB
    enable_audit_logging: true